
<!DOCTYPE html>
<html>
    <head>
         <!-- Bootstrap core CSS -->
    <link href="../static/css/bootstrap.min.css" rel="stylesheet">
        <!-- Custom styles for this template -->
        <link href="../static/css/starter-template.css" rel="stylesheet">
    <title>Training, Test, Validation, ... threads</title>
    </head>
    <body>
    <div class="container">
      
        <h3>Check out some of these threads:</h3>
        </br>
<p><font size="3"><a href="../t1_a1"> Q1 </a></font>: Hi fellow Fellows, does anyone now of any existing, straightforward methods to calculate error bars/confidence intervals for XGBRegressor predictions as applied to time series forecasting (where you can’t do standard randomized cross-validation/bootstrapping due to time stream autocorrelation)?  I've been scouring for one and have only found the following semi-cryptic blog post.   Thanks!  https://www.bigdatarepublic.nl/regression-prediction-intervals-with-xgboost/</p><p><font size="3"><a href="../t1_a2"> Q2 </a></font>: Hi I'm using spark streaming.  I have encountered a problem with ssc.textFileStream()
in my code I write data into hdfs successfully using saAsTextFiles("training/data/training.txt").
However when I use: 
val data = ssc.textFileStream("datadirectory")
data.print()

I cant not print the data during the stream. I have used the following options for "datadirectory":
"training/data/training.txt"
"training/data/training.txt/*"
"training/data/training.txt/*.*"

Any help would be appreciated</p><p><font size="3"><a href="../t1_a3"> Q3 </a></font>: Has anyone worked with survival prediction model before and know what metric best evaluate its accuracy?</p><p><font size="3"><a href="../t1_a4"> Q4 </a></font>: question on cross validation: how many iterations and what k should one do for a multi-iteration k-fold cross validation? (For me I have ~15000 entries for 31 classes of imbalanced data, I used stratified sampling as well as class weight = balanced when using my one v all logistic classifier)</p><p><font size="3"><a href="../t1_a5"> Q5 </a></font>: Hi Fellows, anyone had experience working with flask, pickle, and Heroku?  Two questions. 1. I have a training model (~40mb)  need to load to make predictions per user request, except host on AWS S3, any other way to host this train model file? 2. Loading the model take around 6s, any other way I can improve the efficiency? For a production API, 6s is too much for me.</p><p><font size="3"><a href="../t1_a6"> Q6 </a></font>: Does anyone have experience using this: http://www.pachyderm.io ?  Or built their own data and model management system?</p><p><font size="3"><a href="../t1_a7"> Q7 </a></font>: Just a heads-up as to what Ivan and I have been doing: Decisions as to the preprocessing of the data are mostly resolved (at least on a small subset of the data), and we wrote code for a 3D VGG16 CNN. Just need to preprocess all the data, split into train/test, and see what we get from the model.</p><p><font size="3"><a href="../t1_a8"> Q8 </a></font>: or do you want to know only if 'rb' is present or not? or something else?</p><p><font size="3"><a href="../t1_a9"> Q9 </a></font>: Hi team, I am building a classification model for imbalanced data (1% positive prevalence). We have a lot of data so I am subsampling the negative cases to match the number of positive cases. I plotted the calibration probability plots following this link (http://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py) and the subsampled train &amp; validation curves look good. However, the test data (not subsampled) is essentially just a flat line near zero (slightly upward sloping). Does it make sense to plot the calibration curve for imbalanced test data? Has anyone used CalibratedClassifierCV with imbalanced data? The use case for this model is to provide a ranked list with highest probability at the top. Unfortunately due to the imbalance, the number of false positives greatly exceeds the number of true positives at the top of this list. Any recommendations would be helpful. I can provide more details if needed.</p><p><font size="3"><a href="../t1_a10"> Q10 </a></font>: Would anyone have experience saving a checkpoint model with just the relevant trained weights, ie. the minimal needed to restore the model.  I’m working on trying to package my model while trying to save space.  It’s currently 800megs.  That’s the output of `tf.train.Saver()`.  I’m looking for a way that’s more efficient on model size.  Any input is appreciated. thanks!</p><p><font size="3"><a href="../t1_a11"> Q11 </a></font>: Anyone heading down from SF want to be train buddies?</p>

        </br></br></br>
        
        <center>
            <font size="3" color=#CDC9C9>© 2018 <a href="mailto:duccio.pappadopulo@gmail.com?Subject=You%20screw%20up" target="_top">Duccio Pappadopulo</a> </font>
        </center>
        
        </body>
        
         </div>
    </html>
